#!/usr/bin/env python3
"""
Blip.kr K-POP Schedule Scraper v4 (RSC Payload + Unit Mapping)

blip.krì€ Next.js App Routerë¥¼ ì‚¬ìš©í•˜ë©°, SSR HTML í…Œì´ë¸”ì—ëŠ”
ì…€ë‹¹ ìµœëŒ€ 3ê°œ ì´ë²¤íŠ¸ë§Œ í‘œì‹œ. ì „ì²´ ë°ì´í„°ëŠ” React Server Component
payload (self.__next_f.push)ì— JSONìœ¼ë¡œ í¬í•¨ë¨.

v4 ë³€ê²½ì‚¬í•­:
- í™ˆí˜ì´ì§€ì—ì„œ unitId â†’ ê·¸ë£¹ëª…(í•œê¸€/ì˜ë¬¸) ë§¤í•‘ ë™ì  ìˆ˜ì§‘
- ì´ë²¤íŠ¸ì— unitId í¬í•¨í•˜ì—¬ ê·¸ë£¹ë³„ í•„í„°ë§ ì§€ì›
- schedule.jsonì— units ë§¤í•‘ í…Œì´ë¸” ì¶”ê°€

ìŠ¤í¬ë˜í•‘ ë²”ìœ„: ì „ì›” 1ì¼ ~ ì‹¤í–‰ì¼ë¡œë¶€í„° 1ë…„ í›„ê¹Œì§€
"""

import json
import re
import time
import random
from datetime import datetime, timedelta
from urllib.request import Request, urlopen
from urllib.error import URLError, HTTPError


# â”€â”€â”€ ì¹´í…Œê³ ë¦¬ ì •ì˜ â”€â”€â”€

CATEGORIES = {
    "ì¶•í•˜": "#4ECDC4",
    "ë°œë§¤": "#FF6B6B",
    "ë°©ì†¡": "#FFE66D",
    "êµ¬ë§¤": "#95E1D3",
    "í–‰ì‚¬": "#C7CEEA",
    "ê¸°íƒ€": "#999999",
    "ë¹„ê³µì‹": "#FFB6B9",
    "SNS": "#8EC5FC",
}

# blip.kr typeId â†’ ê¸°ë³¸ ì¹´í…Œê³ ë¦¬ ë§¤í•‘
TYPE_ID_MAP = {
    2: "ë°œë§¤",    # Release, Teaser, MV, Concept Photo ë“±
    4: "ì¶•í•˜",    # ìƒì¼, ê¸°ë…ì¼, ìˆ˜ìƒ, ë°ë·” ê¸°ë… ë“±
}

# ì œëª© í‚¤ì›Œë“œ ê¸°ë°˜ ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ ë³´ì •
CATEGORY_KEYWORDS = {
    "ë°©ì†¡": [
        "ì¸ê¸°ê°€ìš”", "Inkigayo", "ìŒì•…ì¤‘ì‹¬", "MusicCore", "M COUNTDOWN",
        "ë®¤ì§ë±…í¬", "Music Bank", "SHOW CHAMPION", "ìŒì•…ë°©ì†¡", "1ìœ„",
    ],
    "í–‰ì‚¬": [
        "ì½˜ì„œíŠ¸", "Concert", "CONCERT", "íŒ¬ë¯¸íŒ…", "Fan Meeting",
        "TOUR", "Tour", "ì‡¼ì¼€ì´ìŠ¤", "Showcase", "LIVE",
    ],
    "êµ¬ë§¤": [
        "ì˜ˆì•½", "Pre-order", "PRE-ORDER", "êµ¬ë§¤", "Purchase",
        "í‹°ì¼“", "Ticket", "TICKET",
    ],
    "SNS": [
        "V LIVE", "ìœ„ë²„ìŠ¤", "Weverse", "ì¸ìŠ¤íƒ€",
    ],
    "ë°œë§¤": [
        "Release", "ë°œë§¤", "RELEASE", "MV", "Teaser", "TEASER",
        "Concept", "CONCEPT", "Album", "ALBUM", "ê³µê°œ",
    ],
    "ì¶•í•˜": [
        "HAPPY", "DAY!", "ìƒì¼", "birthday", "ê¸°ë…ì¼",
        "ë°ë·”", "ì£¼ë…„", "anniversary", "ìˆ˜ìƒ",
    ],
}

DEFAULT_HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/131.0.0.0 Safari/537.36"
    ),
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
    "Accept-Language": "ko-KR,ko;q=0.9,en;q=0.8",
}


# â”€â”€â”€ RSC Payload ê³µí†µ ë””ì½”ë”© â”€â”€â”€

def decode_rsc_chunk(chunk: str) -> str:
    """JavaScript ì´ì¤‘ ì´ìŠ¤ì¼€ì´í”„ë¥¼ í•´ì œí•˜ì—¬ íŒŒì‹± ê°€ëŠ¥í•œ ë¬¸ìì—´ë¡œ ë³€í™˜"""
    raw = chunk
    raw = raw.replace("\\\\", "\x00BS\x00")
    raw = raw.replace('\\"', '"')
    raw = raw.replace("\\n", "\n")
    raw = raw.replace("\x00BS\x00", "\\")
    return raw


# â”€â”€â”€ ìœ ë‹› ë§¤í•‘ ìˆ˜ì§‘ â”€â”€â”€

def fetch_unit_mapping() -> dict:
    """
    blip.kr í™ˆí˜ì´ì§€ RSC payloadì—ì„œ unitId â†’ ê·¸ë£¹ëª… ë§¤í•‘ ì¶”ì¶œ.

    í™ˆí˜ì´ì§€ì—ëŠ” {"unitId":N,"artistId":N,"isFilter":N,"blipName":"ê·¸ë£¹ëª…",...}
    í˜•íƒœì˜ ì•„í‹°ìŠ¤íŠ¸ ëª©ë¡ì´ í¬í•¨ë¨. names ë°°ì—´ì—ì„œ ì˜ë¬¸ëª…ë„ ì¶”ì¶œ.

    Returns:
        {unitId(int): {"ko": "í•œê¸€ëª…", "en": "ì˜ë¬¸ëª…"}, ...}
    """
    print("ğŸ  í™ˆí˜ì´ì§€ì—ì„œ ìœ ë‹› ë§¤í•‘ ìˆ˜ì§‘ ì¤‘...")

    req = Request("https://blip.kr", headers=DEFAULT_HEADERS)

    try:
        with urlopen(req, timeout=20) as response:
            html = response.read().decode("utf-8")
    except (URLError, HTTPError) as e:
        print(f"  âš ï¸  í™ˆí˜ì´ì§€ ìš”ì²­ ì‹¤íŒ¨: {e}")
        return {}

    rsc_chunks = re.findall(
        r'self\.__next_f\.push\(\[1,"(.*?)"\]\)', html, re.DOTALL
    )

    for chunk in rsc_chunks:
        if "blipName" not in chunk:
            continue

        raw = decode_rsc_chunk(chunk)

        # unitId, blipName(í•œê¸€ëª…) ì¶”ì¶œ
        ko_matches = re.findall(
            r'\{"unitId":(\d+),"artistId":\d+,"isFilter":\d+,"blipName":"([^"]*)"',
            raw,
        )

        # ì˜ë¬¸ëª… ì¶”ì¶œ
        en_matches = re.findall(
            r'\{"code":"en","name":"([^"]*)","unitId":(\d+)\}',
            raw,
        )
        en_map = {}
        for en_name, uid_str in en_matches:
            en_map[int(uid_str)] = en_name

        # ë§¤í•‘ êµ¬ì„±
        unit_map = {}
        for uid_str, ko_name in ko_matches:
            uid = int(uid_str)
            unit_map[uid] = {
                "ko": ko_name,
                "en": en_map.get(uid, ko_name),
            }

        print(f"  âœ… {len(unit_map)}ê°œ ê·¸ë£¹ ë§¤í•‘ í™•ë³´")
        return unit_map

    print("  âš ï¸  í™ˆí˜ì´ì§€ì—ì„œ ìœ ë‹› ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
    return {}


# â”€â”€â”€ RSC Payload ì´ë²¤íŠ¸ íŒŒì‹± â”€â”€â”€

def extract_rsc_events(html: str) -> list[dict]:
    """
    Next.js RSC payloadì—ì„œ ìŠ¤ì¼€ì¤„ ì´ë²¤íŠ¸ ì¶”ì¶œ.
    self.__next_f.push([1, "..."]) ë‚´ì˜ scheduleId ê°ì²´ë“¤ì„ íŒŒì‹±.
    """
    rsc_chunks = re.findall(
        r'self\.__next_f\.push\(\[1,"(.*?)"\]\)', html, re.DOTALL
    )

    for chunk in rsc_chunks:
        if "scheduleId" not in chunk:
            continue

        raw = decode_rsc_chunk(chunk)

        events = []
        pos = 0

        while True:
            obj_start = raw.find('{"scheduleId"', pos)
            if obj_start < 0:
                break

            # ë§¤ì¹­ë˜ëŠ” ì¤‘ê´„í˜¸ ë ì°¾ê¸°
            depth = 0
            obj_end = obj_start
            for j in range(obj_start, min(obj_start + 10000, len(raw))):
                if raw[j] == "{":
                    depth += 1
                elif raw[j] == "}":
                    depth -= 1
                if depth == 0:
                    obj_end = j + 1
                    break

            obj_str = raw[obj_start:obj_end]

            # message í•„ë“œ ë‚´ ì¤„ë°”ê¿ˆ ë“±ìœ¼ë¡œ JSON íŒŒì‹± ì‹¤íŒ¨ ë°©ì§€
            obj_str = re.sub(r'"message":"[^"]*"', '"message":""', obj_str)

            try:
                obj = json.loads(obj_str)
                events.append(obj)
            except json.JSONDecodeError:
                pass

            pos = obj_end + 1

        if events:
            return events

    return []


def classify_event(event: dict) -> str:
    """typeId + ì œëª© í‚¤ì›Œë“œë¡œ ì¹´í…Œê³ ë¦¬ ê²°ì •"""
    type_id = event.get("typeId")
    title = event.get("title", "")

    # í‚¤ì›Œë“œ ê¸°ë°˜ ì„¸ë¶€ ë¶„ë¥˜ (ìš°ì„ )
    for category, keywords in CATEGORY_KEYWORDS.items():
        for kw in keywords:
            if kw in title:
                return category

    # typeId ê¸°ë°˜ ê¸°ë³¸ ë¶„ë¥˜ (fallback)
    return TYPE_ID_MAP.get(type_id, "ê¸°íƒ€")


def parse_events_to_dict(events: list[dict], year: int, month: int) -> dict:
    """RSC ì´ë²¤íŠ¸ ë¦¬ìŠ¤íŠ¸ â†’ {ë‚ ì§œ: [ì´ë²¤íŠ¸]} ë”•ì…”ë„ˆë¦¬ ë³€í™˜"""
    result = {}
    month_prefix = f"{year}-{month:02d}-"

    for event in events:
        start_time = event.get("startTime", "")
        if not start_time:
            continue

        # ISO ì‹œê°„ â†’ KST ë‚ ì§œ ë³€í™˜
        # startTime: "2026-01-31T15:00:00.000Z" (UTC) â†’ KST +9h â†’ 2026-02-01
        try:
            utc_dt = datetime.fromisoformat(start_time.replace("Z", "+00:00"))
            kst_dt = utc_dt + timedelta(hours=9)
            date_key = kst_dt.strftime("%Y-%m-%d")
        except (ValueError, AttributeError):
            continue

        # í•´ë‹¹ ì›”ë§Œ í•„í„°
        if not date_key.startswith(month_prefix):
            continue

        title = event.get("title", "").strip()
        if not title:
            continue

        category = classify_event(event)
        unit_id = event.get("unitId")

        if date_key not in result:
            result[date_key] = []

        # ì¤‘ë³µ ì œê±°
        existing_titles = {e["title"] for e in result[date_key]}
        if title not in existing_titles:
            entry = {
                "title": title,
                "category": category,
            }
            if unit_id is not None:
                entry["unitId"] = unit_id
            result[date_key].append(entry)

    return result


# â”€â”€â”€ HTTP ìš”ì²­ â”€â”€â”€

def fetch_month(year: int, month: int) -> dict:
    """íŠ¹ì • ì›”ì˜ ìŠ¤ì¼€ì¤„ í˜ì´ì§€ì—ì„œ RSC payload ì¶”ì¶œ"""
    url = f"https://blip.kr/schedule?year={year}&month={month}"

    req = Request(url, headers=DEFAULT_HEADERS)

    try:
        with urlopen(req, timeout=20) as response:
            html = response.read().decode("utf-8")

        events = extract_rsc_events(html)

        if not events:
            print(f"  âš ï¸  {year}-{month:02d}: RSC payloadì— ì´ë²¤íŠ¸ ì—†ìŒ")
            return {}

        return parse_events_to_dict(events, year, month)

    except (URLError, HTTPError) as e:
        print(f"  âš ï¸  {year}-{month:02d} ìš”ì²­ ì‹¤íŒ¨: {e}")
        return {}
    except Exception as e:
        print(f"  âš ï¸  {year}-{month:02d} íŒŒì‹± ì˜¤ë¥˜: {e}")
        return {}


# â”€â”€â”€ ë©”ì¸ ìŠ¤í¬ë˜í•‘ â”€â”€â”€

def scrape_schedule() -> dict:
    """ì „ì›” 1ì¼ ~ ì‹¤í–‰ì¼ ê¸°ì¤€ 1ë…„ í›„ê¹Œì§€ ìŠ¤ì¼€ì¤„ ìˆ˜ì§‘"""
    today = datetime.now()

    # ìœ ë‹› ë§¤í•‘ ë¨¼ì € ìˆ˜ì§‘
    unit_map = fetch_unit_mapping()
    time.sleep(random.uniform(1.0, 2.0))

    # ì‹œì‘: ì „ì›” 1ì¼
    if today.month == 1:
        start_year, start_month = today.year - 1, 12
    else:
        start_year, start_month = today.year, today.month - 1

    # ì¢…ë£Œ: ì˜¤ëŠ˜ë¡œë¶€í„° 1ë…„ í›„
    end_date = today + timedelta(days=365)
    end_year, end_month = end_date.year, end_date.month

    print(f"ğŸ“… ìŠ¤í¬ë˜í•‘ ë²”ìœ„: {start_year}-{start_month:02d} ~ {end_year}-{end_month:02d}")

    all_events = {}
    total_months = 0

    year, month = start_year, start_month
    while (year, month) <= (end_year, end_month):
        print(f"  ğŸ”„ {year}-{month:02d} ìˆ˜ì§‘ ì¤‘...")

        month_events = fetch_month(year, month)

        for date_key, event_list in month_events.items():
            if date_key not in all_events:
                all_events[date_key] = []
            existing_titles = {e["title"] for e in all_events[date_key]}
            for event in event_list:
                if event["title"] not in existing_titles:
                    all_events[date_key].append(event)
                    existing_titles.add(event["title"])

        total_months += 1

        # ë‹¤ìŒ ì›”
        if month == 12:
            year, month = year + 1, 1
        else:
            month += 1

        # ìš”ì²­ ê°„ ê°„ê²© (1-2ì´ˆ)
        time.sleep(random.uniform(1.0, 2.0))

    # ë‚ ì§œ ìˆœ ì •ë ¬
    sorted_events = dict(sorted(all_events.items()))

    total_events = sum(len(v) for v in sorted_events.values())
    total_days = len(sorted_events)

    # ì‹¤ì œ ë“±ì¥í•˜ëŠ” unitIdë§Œ í•„í„°ë§í•˜ì—¬ units í…Œì´ë¸” ìƒì„±
    used_unit_ids = set()
    for date_events in sorted_events.values():
        for event in date_events:
            uid = event.get("unitId")
            if uid is not None:
                used_unit_ids.add(uid)

    # units: ì´ë²¤íŠ¸ì— ë“±ì¥í•˜ëŠ” ê·¸ë£¹ë§Œ í¬í•¨ (JSON keyëŠ” string)
    units = {}
    unmapped = 0
    for uid in sorted(used_unit_ids):
        if uid in unit_map:
            units[str(uid)] = unit_map[uid]
        else:
            unmapped += 1
            units[str(uid)] = {"ko": "ê¸°íƒ€ ê·¸ë£¹", "en": "Other"}

    print(f"\nâœ… ìŠ¤í¬ë˜í•‘ ì™„ë£Œ!")
    print(f"   - ìˆ˜ì§‘ ì›”ìˆ˜: {total_months}ê°œì›”")
    print(f"   - ì¼ì • ìˆëŠ” ë‚ : {total_days}ì¼")
    print(f"   - ì´ ì´ë²¤íŠ¸: {total_events}ê°œ")
    print(f"   - ê·¸ë£¹ ìˆ˜: {len(units)}ê°œ (ë§¤í•‘: {len(units)-unmapped}, ê¸°íƒ€: {unmapped})")

    result = {
        "updated_at": today.isoformat(),
        "range": {
            "start": f"{start_year}-{start_month:02d}-01",
            "end": f"{end_year}-{end_month:02d}-{_last_day(end_year, end_month):02d}",
        },
        "categories": list(CATEGORIES.keys()),
        "category_colors": CATEGORIES,
        "units": units,
        "events": sorted_events,
        "stats": {
            "months_scraped": total_months,
            "days_with_events": total_days,
            "total_events": total_events,
            "total_units": len(units),
        },
    }

    return result


def _last_day(year: int, month: int) -> int:
    if month == 12:
        return 31
    return (datetime(year, month + 1, 1) - timedelta(days=1)).day


# â”€â”€â”€ ì €ì¥ â”€â”€â”€

def save_json(data: dict, filename: str = "schedule.json"):
    # schedule.jsonì—ì„œ scheduleId ì œì™¸ (íŒŒì¼ í¬ê¸° ì ˆì•½)
    clean_data = json.loads(json.dumps(data))
    for date_key in clean_data.get("events", {}):
        for event in clean_data["events"][date_key]:
            event.pop("scheduleId", None)

    with open(filename, "w", encoding="utf-8") as f:
        json.dump(clean_data, f, ensure_ascii=False, indent=2)
    print(f"ğŸ’¾ {filename} ì €ì¥ ì™„ë£Œ")


# â”€â”€â”€ ë©”ì¸ â”€â”€â”€

def main():
    print("ğŸ¬ Blip.kr Schedule Scraper v4 (RSC + Unit Mapping) ì‹œì‘\n")

    data = scrape_schedule()

    if data and data["stats"]["total_events"] > 0:
        save_json(data)
        print(f"\nğŸ“Š ì €ì¥: ./schedule.json")
        print(f"ğŸ“ˆ ê°±ì‹ : {data['updated_at']}")
    else:
        print("\nâŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨ ë˜ëŠ” ì´ë²¤íŠ¸ 0ê±´")
        save_json(data or {"error": "no data", "updated_at": datetime.now().isoformat()})


if __name__ == "__main__":
    main()